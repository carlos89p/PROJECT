{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whisper implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlosillanaldariz/miniconda3/lib/python3.11/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción agregada a 'transcriptions.csv':\n",
      " Estamos un pouco viejas e o que hacemos é sair a tomar café. Pero antes solíamos hacer máas actividades como ir a jugar a palas, é un deporte típico Vasco, o ir a jugar a fútbol, o hacer actividades así deportivas.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar modelo de Whisper (elige \"tiny\", \"base\", \"small\", \"medium\" o \"large\")\n",
    "model = whisper.load_model(\"small\")  # Puedes cambiar el tamaño del modelo\n",
    "\n",
    "# Ruta del archivo de audio (modifica con tu archivo)\n",
    "audio_path = \"audio_test_2.mp3\"  # Puede ser .mp3, .wav, .m4a, .ogg, etc.\n",
    "\n",
    "# Transcribir el audio\n",
    "result = model.transcribe(audio_path)\n",
    "\n",
    "# Extraer el texto transcrito\n",
    "transcription = result[\"text\"]\n",
    "\n",
    "# Definir nombre del archivo CSV\n",
    "csv_file = \"transcriptions.csv\"\n",
    "\n",
    "# Verificar si el archivo existe para escribir encabezados solo si es la primera vez\n",
    "file_exists = os.path.isfile(csv_file)\n",
    "\n",
    "# Crear DataFrame con la nueva transcripción\n",
    "df = pd.DataFrame({\"Texto\": [transcription]})\n",
    "\n",
    "# Guardar en el CSV sin sobrescribir datos anteriores (modo 'a' de append)\n",
    "df.to_csv(csv_file, mode='a', header=not file_exists, index=False, encoding='utf-8')\n",
    "\n",
    "# Imprimir la transcripción\n",
    "print(\"Transcripción agregada a 'transcriptions.csv':\")\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Estamos', 'un', 'pouco', 'viejas', 'e', 'o', 'que', 'hacemos', 'é', 'sair', 'a', 'tomar', 'café', '.', 'Pero', 'antes', 'solíamos', 'hacer', 'máas', 'actividades', 'como', 'ir', 'a', 'jugar', 'a', 'palas', ',', 'é', 'un', 'deporte', 'típico', 'Vasco', ',', 'o', 'ir', 'a', 'jugar', 'a', 'fútbol', ',', 'o', 'hacer', 'actividades', 'así', 'deportivas', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "# Load the text from the csv file\n",
    "df = pd.read_csv(\"transcriptions.csv\")\n",
    "\n",
    "# Tokenize the last entry in the 'Texto' column\n",
    "if not df.empty and 'Texto' in df.columns:\n",
    "    text = df['Texto'].iloc[-1]  # Get the last entry\n",
    "    tokens = nltk.word_tokenize(str(text))  # Convert to string in case of NaN\n",
    "    print(tokens)\n",
    "else:\n",
    "    print(\"The CSV file is empty or does not contain the 'Texto' column.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
