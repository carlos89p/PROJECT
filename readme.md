# ğŸš˜ Autonomous Driving Assistant

A modular, privacy-preserving intelligent assistant for autonomous driving â€” combining speech recognition, natural language processing, route optimization, and real-time object detection.

## ğŸ§  Overview

This project integrates state-of-the-art AI technologies into a unified system to enhance autonomous driving assistance through:

- ğŸ”Š **Conversational Interaction**: A locally-deployed Large Language Model (LLM) provides real-time recommendations based on vehicle and environment conditions.
- ğŸ—ºï¸ **Speech-Based Route Planning**: Transcribes spoken origin/destination, extracts cities using Named Entity Recognition (NER), corrects with Levenshtein distance, and computes routes using Greedy Best-First Search.
- ğŸ§â€â™‚ï¸ **Visual Perception**: Real-time object detection using YOLOv8 models for pedestrians and traffic signs.

All components run **fully locally**, ensuring privacy and autonomy.

---

## ğŸ§© Project Structure

autonomous-driving-assistant/
â”œâ”€â”€ chatbot/ # Conversational assistant with Mistral LLM
â”œâ”€â”€ route_planner/ # Audio transcription, NER, route computation
â”œâ”€â”€ object_detection/ # YOLOv8 training and inference
â”œâ”€â”€ assets/ # Sample audio, images, route maps
â”œâ”€â”€ data/ # Graph of cities, datasets, labels
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app.py # Unified Streamlit interface (optional)
â””â”€â”€ README.md

yaml
Copiar
Editar

---

## âš™ï¸ Technologies Used

| Module                    | Technology                                                                 |
|--------------------------|----------------------------------------------------------------------------|
| Speech Recognition       | [OpenAI Whisper](https://github.com/openai/whisper)                        |
| Named Entity Recognition | [Hugging Face Transformers (Roberta NER)](https://huggingface.co/AventIQ-AI/roberta-named-entity-recognition) |
| String Matching          | Levenshtein Distance (fuzzy matching)                                      |
| Route Planning           | Greedy Best-First Search on a custom city graph                            |
| Object Detection         | [YOLOv8](https://github.com/ultralytics/ultralytics) via Roboflow datasets |
| LLM Assistant            | [Mistral](https://mistral.ai) deployed locally                             |
| Interface (optional)     | [Streamlit](https://streamlit.io/)                                         |

---

## ğŸš€ How to Run

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/autonomous-driving-assistant.git
   cd autonomous-driving-assistant
Create and activate virtual environment:

bash
Copiar
Editar
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
Install dependencies:

bash
Copiar
Editar
pip install -r requirements.txt
Run the modules:

Chatbot:

bash
Copiar
Editar
cd chatbot
python chatbot.py
Route Planner:

bash
Copiar
Editar
cd route_planner
python planner.py
Object Detection:

bash
Copiar
Editar
cd object_detection
python detect.py
(Optional) Unified Interface:

bash
Copiar
Editar
streamlit run app.py
ğŸ” Sample Results
âœ… Mistral-based assistant gives coherent advice on vehicle and road conditions.

âœ… Robust speech recognition and city name extraction using Whisper + NER + Levenshtein distance.

âœ… Real-time object detection of pedestrians and traffic signs using YOLOv8.

ğŸ§  Fully local processing â€” no cloud, no API dependencies.

ğŸ“š References
OpenAI Whisper

Hugging Face NER

YOLOv8 on Roboflow

Mistral LLM

ğŸ§‘â€ğŸ’» Author
Carlos IllÃ¡n Aldariz
Student of Intelligent Systems Engineering at UIE, A CoruÃ±a (Spain)

ğŸ“œ License
This project is for academic and research purposes. Please cite the repository or author if used in derivative work.

yaml
Copiar
Editar

---

Â¿Te gustarÃ­a que te genere automÃ¡ticamente tambiÃ©n el archivo `requirements.txt` bÃ¡sico para acompaÃ±ar este README?